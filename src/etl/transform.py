import pandas as pd
import numpy as np
from datetime import datetime
import pytz
import logging
from typing import Dict, List, Tuple
import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent.parent))
from config.settings import config

class SafraTransformer:
    """Transformador baseado APENAS nas colunas reais do Relatorio_Diario"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.brasilia_tz = pytz.timezone('America/Sao_Paulo')
    
    def processar_dados_completo(self, relatorio_diario: pd.DataFrame, 
                                base_historica: pd.DataFrame) -> pd.DataFrame:
        """Processamento usando APENAS colunas existentes"""
        try:
            self.logger.info("üîÑ Iniciando processamento com colunas reais")
            
            # 1. Limpar e padronizar dados
            relatorio_limpo = self._limpar_dados_reais(relatorio_diario.copy())
            
            # 2. Aplicar filtros b√°sicos
            relatorio_filtrado = self._aplicar_filtros_basicos(relatorio_limpo)
            
            # 3. Padronizar campos existentes
            relatorio_processado = self._padronizar_campos_reais(relatorio_filtrado)
            
            # 4. Merge simples com hist√≥rico
            if not base_historica.empty:
                resultado = self._merge_simples(relatorio_processado, base_historica)
            else:
                resultado = relatorio_processado.copy()
                self.logger.info("üìù Primeira execu√ß√£o - criando nova base")
            
            # 5. Valida√ß√µes finais
            resultado = self._validacoes_finais(resultado)
            
            self.logger.info(f"‚úÖ Processamento conclu√≠do: {len(resultado):,} registros")
            return resultado
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro no processamento: {e}")
            raise
    
    def _limpar_dados_reais(self, df: pd.DataFrame) -> pd.DataFrame:
        """Limpeza usando apenas colunas que existem"""
        self.logger.info("üßπ Limpando dados reais")
        
        # Remover linhas completamente vazias
        df = df.dropna(how='all')
        
        # Limpar campos de texto
        for col in df.select_dtypes(include=['object']).columns:
            df[col] = df[col].astype(str).str.strip()
            df[col] = df[col].replace(['nan', 'None', '', 'NaT'], np.nan)
        
        # Padronizar Provider (campo cr√≠tico)
        if 'Provider' in df.columns:
            df['Provider'] = df['Provider'].str.strip()
            self.logger.info("‚úÖ Provider padronizado")
        
        return df
    
    def _aplicar_filtros_basicos(self, df: pd.DataFrame) -> pd.DataFrame:
        """Filtros b√°sicos usando apenas colunas existentes"""
        self.logger.info("üîç Aplicando filtros b√°sicos")
        
        tamanho_inicial = len(df)
        
        # Filtrar TEFTI
        if 'Provider' in df.columns:
            df = df[df['Provider'] != 'TEFTI']
            self.logger.info("üö´ TEFTI removido")
        
        # Filtrar por SLA m√≠nimo (se existir)
        if 'SLA Cliente' in df.columns:
            df = df[pd.to_numeric(df['SLA Cliente'], errors='coerce') >= config.SLA_CLIENTE_MINIMO]
            self.logger.info(f"üìä Filtro SLA >= {config.SLA_CLIENTE_MINIMO}")
        
        # Manter apenas registros com Ordem PagBank v√°lida
        if 'Ordem PagBank' in df.columns:
            df = df[df['Ordem PagBank'].notna()]
        
        registros_removidos = tamanho_inicial - len(df)
        self.logger.info(f"üìâ Registros removidos: {registros_removidos:,}")
        
        return df
    
    def _padronizar_campos_reais(self, df: pd.DataFrame) -> pd.DataFrame:
        """Padroniza apenas campos que existem"""
        self.logger.info("üîß Padronizando campos existentes")
        
        # Adicionar timestamp de processamento
        df['Data_Processamento'] = datetime.now(self.brasilia_tz)
        
        # Converter tipos seguros
        df = self._converter_tipos_reais(df)
        
        return df
    
    def _converter_tipos_reais(self, df: pd.DataFrame) -> pd.DataFrame:
        """Convers√£o segura apenas das colunas que existem"""
        
        # N√∫meros inteiros (apenas se existirem)
        colunas_int = ['Ordem PagBank', 'Ordem SAP', 'SLA Cliente', 'SLA Log√≠stica', 
                      'Ordem Workfinity', 'C√≥d. √öltimo Tracking']
        for col in colunas_int:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64')
        
        # Datas (apenas se existirem)
        colunas_data = ['Cria√ß√£o da Ordem', 'In√≠cio Indoor', 'Data √ölt. Tracking Indoor', 
                       'In√≠cio Transporte', 'Data √ölt. Tracking Transporte', 'Data Tracking', 
                       'Data Coleta', 'Previs√£o do Gerenciador']
        for col in colunas_data:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True)
        
        # Textos (apenas se existirem)
        colunas_texto = ['Provider', 'Status da Ordem', 'Tipo da Ordem', 'Estado', 
                        'Cidade', 'CEP', 'Transportadora', '√öltimo Tracking']
        for col in colunas_texto:
            if col in df.columns:
                df[col] = df[col].astype('string')
        
        return df
    
    def _merge_simples(self, relatorio_novo: pd.DataFrame, 
                      base_historica: pd.DataFrame) -> pd.DataFrame:
        """Merge simples preservando hist√≥rico"""
        self.logger.info("üîÑ Merge com base hist√≥rica")
        
        chave_primaria = 'Ordem PagBank'
        
        # Combinar dados novos com hist√≥rico
        chaves_historicas = set(base_historica[chave_primaria].dropna())
        chaves_novas = set(relatorio_novo[chave_primaria].dropna())
        
        # Registros s√≥ no hist√≥rico (manter)
        so_historico = chaves_historicas - chaves_novas
        df_so_historico = base_historica[
            base_historica[chave_primaria].isin(so_historico)
        ].copy()
        
        # Registros novos ou atualizados
        df_atualizados = relatorio_novo.copy()
        
        # Combinar
        resultado_final = pd.concat([df_so_historico, df_atualizados], ignore_index=True)
        
        self.logger.info(f"üìä Merge conclu√≠do: {len(resultado_final):,} registros")
        
        return resultado_final
    
    def _validacoes_finais(self, df: pd.DataFrame) -> pd.DataFrame:
        """Valida√ß√µes finais"""
        self.logger.info("‚úÖ Valida√ß√µes finais")
        
        # Remover duplicatas por Ordem PagBank
        tamanho_antes = len(df)
        df = df.drop_duplicates(subset=['Ordem PagBank'], keep='last')
        duplicatas_removidas = tamanho_antes - len(df)
        
        if duplicatas_removidas > 0:
            self.logger.warning(f"‚ö†Ô∏è Duplicatas removidas: {duplicatas_removidas}")
        
        # Ordenar por data de processamento
        if 'Data_Processamento' in df.columns:
            df = df.sort_values('Data_Processamento', ascending=False)
        
        return df
